{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "037ca805-d1fb-4fbb-9881-0bd4ec8cf39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import layers, models\n",
    "from glob import glob\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b646843-35e9-4cb3-b722-2453f92b930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "IMG_SIZE = (384, 128)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "NUM_CLASSES = 3\n",
    "DATA_DIR = \"training_data\"  # path to your folder with 0/, 1/, 2/\n",
    "TEST_DATA_DIR = \"test_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2354a1a7-2a1e-4db2-94db-2f2d08f7e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Resize & Pad Function ===\n",
    "def resize_and_pad(img, target_size=(128, 384), pad_color=0):\n",
    "    h, w = img.shape[:2]\n",
    "    scale = target_size[1] / w\n",
    "    new_w = target_size[1]\n",
    "    new_h = int(h * scale)\n",
    "    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    delta_h = target_size[0] - new_h\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, 0, 0, cv2.BORDER_CONSTANT, value=[pad_color]*3)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b5bad5d-cb3f-433c-a59e-ad8cfb022760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Custom Data Generator ===\n",
    "class PaddedImageSequence(Sequence):\n",
    "    def __init__(self, image_paths, labels, batch_size, target_size, num_classes, shuffle=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            temp = list(zip(self.image_paths, self.labels))\n",
    "            random.shuffle(temp)\n",
    "            self.image_paths, self.labels = zip(*temp)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_paths = self.image_paths[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_labels = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "        for path, label in zip(batch_paths, batch_labels):\n",
    "            img = cv2.imread(path)\n",
    "            img = resize_and_pad(img, target_size=self.target_size)\n",
    "            img = img.astype(\"float32\") / 255.0\n",
    "            X.append(img)\n",
    "            y.append(tf.keras.utils.to_categorical(label, num_classes=self.num_classes))\n",
    "\n",
    "        return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "862efa22-ccc8-4fc5-b86d-a269abaa7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Prepare Dataset ===\n",
    "paths = glob(f\"{DATA_DIR}/*/*.png\")\n",
    "labels = [int(Path(p).parent.name) for p in paths]\n",
    "\n",
    "# Split manually\n",
    "split_idx = int(0.8 * len(paths))\n",
    "train_paths, val_paths = paths[:split_idx], paths[split_idx:]\n",
    "train_labels, val_labels = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "train_gen = PaddedImageSequence(train_paths, train_labels, batch_size=BATCH_SIZE, target_size=IMG_SIZE, num_classes=NUM_CLASSES)\n",
    "val_gen = PaddedImageSequence(val_paths, val_labels, batch_size=BATCH_SIZE, target_size=IMG_SIZE, num_classes=NUM_CLASSES, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e34c4c0-9005-469f-a5d5-596d1709ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model ===\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d410cab1-6dc4-4b58-b304-9b6c8a25b3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 513ms/step - accuracy: 0.4040 - loss: 1.0727 - val_accuracy: 0.0000e+00 - val_loss: 1.2813\n",
      "Epoch 2/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 501ms/step - accuracy: 0.5037 - loss: 1.0150 - val_accuracy: 0.0000e+00 - val_loss: 1.6159\n",
      "Epoch 3/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 507ms/step - accuracy: 0.8122 - loss: 0.5995 - val_accuracy: 1.0000 - val_loss: 0.2363\n",
      "Epoch 4/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 552ms/step - accuracy: 0.9408 - loss: 0.1130 - val_accuracy: 1.0000 - val_loss: 0.1122\n",
      "Epoch 5/5\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 537ms/step - accuracy: 0.9919 - loss: 0.0381 - val_accuracy: 1.0000 - val_loss: 0.0071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x134d47650>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Train ===\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b65c7a44-9368-404e-a60a-7a817fd6a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save Model ===\n",
    "model.save(\"digit_circled_classifier.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70577fec-bdfd-42c7-96d1-d4fa9f151bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step\n",
      "\n",
      "=== Test Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        54\n",
      "           1       1.00      1.00      1.00        67\n",
      "           2       1.00      1.00      1.00        86\n",
      "\n",
      "    accuracy                           1.00       207\n",
      "   macro avg       1.00      1.00      1.00       207\n",
      "weighted avg       1.00      1.00      1.00       207\n",
      "\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[54  0  0]\n",
      " [ 0 67  0]\n",
      " [ 0  0 86]]\n"
     ]
    }
   ],
   "source": [
    "# === Evaluate on Test Set ===\n",
    "test_paths = glob(f\"{TEST_DATA_DIR}/*/*.png\")\n",
    "test_labels = [int(Path(p).parent.name) for p in test_paths]\n",
    "test_gen = PaddedImageSequence(test_paths, test_labels, batch_size=BATCH_SIZE, target_size=IMG_SIZE, num_classes=NUM_CLASSES, shuffle=False)\n",
    "\n",
    "pred_probs = model.predict(test_gen)\n",
    "pred_classes = np.argmax(pred_probs, axis=1)\n",
    "true_classes = np.array(test_labels)\n",
    "\n",
    "print(\"\\n=== Test Classification Report ===\")\n",
    "print(classification_report(true_classes, pred_classes))\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(true_classes, pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c87d5-a295-4a5c-a25d-49861e486c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0775d72-f91f-4369-bc3c-cd01e873abb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
